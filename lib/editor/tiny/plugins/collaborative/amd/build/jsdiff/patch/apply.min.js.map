{"version":3,"file":"apply.min.js","sources":["../../../src/jsdiff/patch/apply.js"],"sourcesContent":["import {hasOnlyWinLineEndings, hasOnlyUnixLineEndings} from '../util/string';\nimport {isWin, isUnix, unixToWin, winToUnix} from './line-endings';\nimport {parsePatch} from './parse';\nimport distanceIterator from '../util/distance-iterator';\n\nexport function applyPatch(source, uniDiff, options = {}) {\n  if (typeof uniDiff === 'string') {\n    uniDiff = parsePatch(uniDiff);\n  }\n\n  if (Array.isArray(uniDiff)) {\n    if (uniDiff.length > 1) {\n      throw new Error('applyPatch only works with a single input.');\n    }\n\n    uniDiff = uniDiff[0];\n  }\n\n  if (options.autoConvertLineEndings || options.autoConvertLineEndings == null) {\n    if (hasOnlyWinLineEndings(source) && isUnix(uniDiff)) {\n      uniDiff = unixToWin(uniDiff);\n    } else if (hasOnlyUnixLineEndings(source) && isWin(uniDiff)) {\n      uniDiff = winToUnix(uniDiff);\n    }\n  }\n\n  // Apply the diff to the input\n  let lines = source.split('\\n'),\n      hunks = uniDiff.hunks,\n\n      compareLine = options.compareLine || ((lineNumber, line, operation, patchContent) => line === patchContent),\n      fuzzFactor = options.fuzzFactor || 0,\n      minLine = 0;\n\n  if (fuzzFactor < 0 || !Number.isInteger(fuzzFactor)) {\n    throw new Error('fuzzFactor must be a non-negative integer');\n  }\n\n  // Special case for empty patch.\n  if (!hunks.length) {\n    return source;\n  }\n\n  // Before anything else, handle EOFNL insertion/removal. If the patch tells us to make a change\n  // to the EOFNL that is redundant/impossible - i.e. to remove a newline that's not there, or add a\n  // newline that already exists - then we either return false and fail to apply the patch (if\n  // fuzzFactor is 0) or simply ignore the problem and do nothing (if fuzzFactor is >0).\n  // If we do need to remove/add a newline at EOF, this will always be in the final hunk:\n  let prevLine = '',\n      removeEOFNL = false,\n      addEOFNL = false;\n  for (let i = 0; i < hunks[hunks.length - 1].lines.length; i++) {\n    const line = hunks[hunks.length - 1].lines[i];\n    if (line[0] == '\\\\') {\n      if (prevLine[0] == '+') {\n        removeEOFNL = true;\n      } else if (prevLine[0] == '-') {\n        addEOFNL = true;\n      }\n    }\n    prevLine = line;\n  }\n  if (removeEOFNL) {\n    if (addEOFNL) {\n      // This means the final line gets changed but doesn't have a trailing newline in either the\n      // original or patched version. In that case, we do nothing if fuzzFactor > 0, and if\n      // fuzzFactor is 0, we simply validate that the source file has no trailing newline.\n      if (!fuzzFactor && lines[lines.length - 1] == '') {\n        return false;\n      }\n    } else if (lines[lines.length - 1] == '') {\n      lines.pop();\n    } else if (!fuzzFactor) {\n      return false;\n    }\n  } else if (addEOFNL) {\n    if (lines[lines.length - 1] != '') {\n      lines.push('');\n    } else if (!fuzzFactor) {\n      return false;\n    }\n  }\n\n  /**\n   * Checks if the hunk can be made to fit at the provided location with at most `maxErrors`\n   * insertions, substitutions, or deletions, while ensuring also that:\n   * - lines deleted in the hunk match exactly, and\n   * - wherever an insertion operation or block of insertion operations appears in the hunk, the\n   *   immediately preceding and following lines of context match exactly\n   *\n   * `toPos` should be set such that lines[toPos] is meant to match hunkLines[0].\n   *\n   * If the hunk can be applied, returns an object with properties `oldLineLastI` and\n   * `replacementLines`. Otherwise, returns null.\n   */\n  function applyHunk(\n    hunkLines,\n    toPos,\n    maxErrors,\n    hunkLinesI = 0,\n    lastContextLineMatched = true,\n    patchedLines = [],\n    patchedLinesLength = 0,\n  ) {\n    let nConsecutiveOldContextLines = 0;\n    let nextContextLineMustMatch = false;\n    for (; hunkLinesI < hunkLines.length; hunkLinesI++) {\n      let hunkLine = hunkLines[hunkLinesI],\n          operation = (hunkLine.length > 0 ? hunkLine[0] : ' '),\n          content = (hunkLine.length > 0 ? hunkLine.substr(1) : hunkLine);\n\n      if (operation === '-') {\n        if (compareLine(toPos + 1, lines[toPos], operation, content)) {\n          toPos++;\n          nConsecutiveOldContextLines = 0;\n        } else {\n          if (!maxErrors || lines[toPos] == null) {\n            return null;\n          }\n          patchedLines[patchedLinesLength] = lines[toPos];\n          return applyHunk(\n            hunkLines,\n            toPos + 1,\n            maxErrors - 1,\n            hunkLinesI,\n            false,\n            patchedLines,\n            patchedLinesLength + 1,\n          );\n        }\n      }\n\n      if (operation === '+') {\n        if (!lastContextLineMatched) {\n          return null;\n        }\n        patchedLines[patchedLinesLength] = content;\n        patchedLinesLength++;\n        nConsecutiveOldContextLines = 0;\n        nextContextLineMustMatch = true;\n      }\n\n      if (operation === ' ') {\n        nConsecutiveOldContextLines++;\n        patchedLines[patchedLinesLength] = lines[toPos];\n        if (compareLine(toPos + 1, lines[toPos], operation, content)) {\n          patchedLinesLength++;\n          lastContextLineMatched = true;\n          nextContextLineMustMatch = false;\n          toPos++;\n        } else {\n          if (nextContextLineMustMatch || !maxErrors) {\n            return null;\n          }\n\n          // Consider 3 possibilities in sequence:\n          // 1. lines contains a *substitution* not included in the patch context, or\n          // 2. lines contains an *insertion* not included in the patch context, or\n          // 3. lines contains a *deletion* not included in the patch context\n          // The first two options are of course only possible if the line from lines is non-null -\n          // i.e. only option 3 is possible if we've overrun the end of the old file.\n          return (\n            lines[toPos] && (\n              applyHunk(\n                hunkLines,\n                toPos + 1,\n                maxErrors - 1,\n                hunkLinesI + 1,\n                false,\n                patchedLines,\n                patchedLinesLength + 1\n              ) || applyHunk(\n                hunkLines,\n                toPos + 1,\n                maxErrors - 1,\n                hunkLinesI,\n                false,\n                patchedLines,\n                patchedLinesLength + 1\n              )\n            ) || applyHunk(\n              hunkLines,\n              toPos,\n              maxErrors - 1,\n              hunkLinesI + 1,\n              false,\n              patchedLines,\n              patchedLinesLength\n            )\n          );\n        }\n      }\n    }\n\n    // Before returning, trim any unmodified context lines off the end of patchedLines and reduce\n    // toPos (and thus oldLineLastI) accordingly. This allows later hunks to be applied to a region\n    // that starts in this hunk's trailing context.\n    patchedLinesLength -= nConsecutiveOldContextLines;\n    toPos -= nConsecutiveOldContextLines;\n    patchedLines.length = patchedLinesLength;\n    return {\n      patchedLines,\n      oldLineLastI: toPos - 1\n    };\n  }\n\n  const resultLines = [];\n\n  // Search best fit offsets for each hunk based on the previous ones\n  let prevHunkOffset = 0;\n  for (let i = 0; i < hunks.length; i++) {\n    const hunk = hunks[i];\n    let hunkResult;\n    let maxLine = lines.length - hunk.oldLines + fuzzFactor;\n    let toPos;\n    for (let maxErrors = 0; maxErrors <= fuzzFactor; maxErrors++) {\n      toPos = hunk.oldStart + prevHunkOffset - 1;\n      let iterator = distanceIterator(toPos, minLine, maxLine);\n      for (; toPos !== undefined; toPos = iterator()) {\n        hunkResult = applyHunk(hunk.lines, toPos, maxErrors);\n        if (hunkResult) {\n          break;\n        }\n      }\n      if (hunkResult) {\n        break;\n      }\n    }\n\n    if (!hunkResult) {\n      return false;\n    }\n\n    // Copy everything from the end of where we applied the last hunk to the start of this hunk\n    for (let i = minLine; i < toPos; i++) {\n      resultLines.push(lines[i]);\n    }\n\n    // Add the lines produced by applying the hunk:\n    for (let i = 0; i < hunkResult.patchedLines.length; i++) {\n      const line = hunkResult.patchedLines[i];\n      resultLines.push(line);\n    }\n\n    // Set lower text limit to end of the current hunk, so next ones don't try\n    // to fit over already patched text\n    minLine = hunkResult.oldLineLastI + 1;\n\n    // Note the offset between where the patch said the hunk should've applied and where we\n    // applied it, so we can adjust future hunks accordingly:\n    prevHunkOffset = toPos + 1 - hunk.oldStart;\n  }\n\n  // Copy over the rest of the lines from the old text\n  for (let i = minLine; i < lines.length; i++) {\n    resultLines.push(lines[i]);\n  }\n\n  return resultLines.join('\\n');\n}\n\n// Wrapper that supports multiple file patches via callbacks.\nexport function applyPatches(uniDiff, options) {\n  if (typeof uniDiff === 'string') {\n    uniDiff = parsePatch(uniDiff);\n  }\n\n  let currentIndex = 0;\n  function processIndex() {\n    let index = uniDiff[currentIndex++];\n    if (!index) {\n      return options.complete();\n    }\n\n    options.loadFile(index, function(err, data) {\n      if (err) {\n        return options.complete(err);\n      }\n\n      let updatedContent = applyPatch(data, index, options);\n      options.patched(index, updatedContent, function(err) {\n        if (err) {\n          return options.complete(err);\n        }\n\n        processIndex();\n      });\n    });\n  }\n  processIndex();\n}\n"],"names":["applyPatch","source","uniDiff","options","Array","isArray","length","Error","autoConvertLineEndings","lines","split","hunks","compareLine","lineNumber","line","operation","patchContent","fuzzFactor","minLine","Number","isInteger","prevLine","removeEOFNL","addEOFNL","i","pop","push","applyHunk","hunkLines","toPos","maxErrors","hunkLinesI","lastContextLineMatched","patchedLines","patchedLinesLength","nConsecutiveOldContextLines","nextContextLineMustMatch","hunkLine","content","substr","oldLineLastI","resultLines","prevHunkOffset","hunk","hunkResult","maxLine","oldLines","oldStart","iterator","undefined","join","currentIndex","processIndex","index","complete","loadFile","err","data","updatedContent","patched"],"mappings":"sNAKgBA,WAAWC,OAAQC,aAASC,+DAAU,MAC7B,iBAAZD,UACTA,SAAU,qBAAWA,UAGnBE,MAAMC,QAAQH,SAAU,IACtBA,QAAQI,OAAS,QACb,IAAIC,MAAM,8CAGlBL,QAAUA,QAAQ,IAGhBC,QAAQK,wBAA4D,MAAlCL,QAAQK,2BACxC,iCAAsBP,UAAW,uBAAOC,SAC1CA,SAAU,0BAAUA,UACX,kCAAuBD,UAAW,sBAAMC,WACjDA,SAAU,0BAAUA,eAKpBO,MAAQR,OAAOS,MAAM,MACrBC,MAAQT,QAAQS,MAEhBC,YAAcT,QAAQS,eAAiBC,WAAYC,KAAMC,UAAWC,eAAiBF,OAASE,cAC9FC,WAAad,QAAQc,YAAc,EACnCC,QAAU,KAEVD,WAAa,IAAME,OAAOC,UAAUH,kBAChC,IAAIV,MAAM,iDAIbI,MAAML,cACFL,WAQLoB,SAAW,GACXC,aAAc,EACdC,UAAW,MACV,IAAIC,EAAI,EAAGA,EAAIb,MAAMA,MAAML,OAAS,GAAGG,MAAMH,OAAQkB,IAAK,OACvDV,KAAOH,MAAMA,MAAML,OAAS,GAAGG,MAAMe,GAC5B,MAAXV,KAAK,KACY,KAAfO,SAAS,GACXC,aAAc,EACU,KAAfD,SAAS,KAClBE,UAAW,IAGfF,SAAWP,QAETQ,gBACEC,cAIGN,YAAyC,IAA3BR,MAAMA,MAAMH,OAAS,UAC/B,OAEJ,GAA+B,IAA3BG,MAAMA,MAAMH,OAAS,GAC9BG,MAAMgB,WACD,IAAKR,kBACH,OAEJ,GAAIM,YACsB,IAA3Bd,MAAMA,MAAMH,OAAS,GACvBG,MAAMiB,KAAK,SACN,IAAKT,kBACH,WAgBFU,UACPC,UACAC,MACAC,eACAC,kEAAa,EACbC,kFACAC,oEAAe,GACfC,0EAAqB,EAEjBC,4BAA8B,EAC9BC,0BAA2B,OACxBL,WAAaH,UAAUtB,OAAQyB,aAAc,KAC9CM,SAAWT,UAAUG,YACrBhB,UAAasB,SAAS/B,OAAS,EAAI+B,SAAS,GAAK,IACjDC,QAAWD,SAAS/B,OAAS,EAAI+B,SAASE,OAAO,GAAKF,YAExC,MAAdtB,UAAmB,KACjBH,YAAYiB,MAAQ,EAAGpB,MAAMoB,OAAQd,UAAWuB,gBAI7CR,WAA6B,MAAhBrB,MAAMoB,QAGxBI,aAAaC,oBAAsBzB,MAAMoB,OAClCF,UACLC,UACAC,MAAQ,EACRC,UAAY,EACZC,YACA,EACAE,aACAC,mBAAqB,IAVd,KAJTL,QACAM,4BAA8B,KAkBhB,MAAdpB,UAAmB,KAChBiB,8BACI,KAETC,aAAaC,oBAAsBI,QACnCJ,qBACAC,4BAA8B,EAC9BC,0BAA2B,KAGX,MAAdrB,UAAmB,IACrBoB,8BACAF,aAAaC,oBAAsBzB,MAAMoB,QACrCjB,YAAYiB,MAAQ,EAAGpB,MAAMoB,OAAQd,UAAWuB,gBAM9CF,2BAA6BN,UACxB,KAUPrB,MAAMoB,SACJF,UACEC,UACAC,MAAQ,EACRC,UAAY,EACZC,WAAa,GACb,EACAE,aACAC,mBAAqB,IAClBP,UACHC,UACAC,MAAQ,EACRC,UAAY,EACZC,YACA,EACAE,aACAC,mBAAqB,KAEpBP,UACHC,UACAC,MACAC,UAAY,EACZC,WAAa,GACb,EACAE,aACAC,oBAzCJA,qBACAF,wBAAyB,EACzBI,0BAA2B,EAC3BP,gBAgDNK,oBAAsBC,4BACtBN,OAASM,4BACTF,aAAa3B,OAAS4B,mBACf,CACLD,aAAAA,aACAO,aAAcX,MAAQ,SAIpBY,YAAc,OAGhBC,eAAiB,MAChB,IAAIlB,EAAI,EAAGA,EAAIb,MAAML,OAAQkB,IAAK,OAC/BmB,KAAOhC,MAAMa,OACfoB,WAEAf,MADAgB,QAAUpC,MAAMH,OAASqC,KAAKG,SAAW7B,eAExC,IAAIa,UAAY,EAAGA,WAAab,WAAYa,YAAa,CAC5DD,MAAQc,KAAKI,SAAWL,eAAiB,MACrCM,UAAW,6BAAiBnB,MAAOX,QAAS2B,mBAC/BI,IAAVpB,QACLe,WAAajB,UAAUgB,KAAKlC,MAAOoB,MAAOC,YACtCc,YAFsBf,MAAQmB,eAMhCJ,qBAKDA,kBACI,MAIJ,IAAIpB,EAAIN,QAASM,EAAIK,MAAOL,IAC/BiB,YAAYf,KAAKjB,MAAMe,QAIpB,IAAIA,EAAI,EAAGA,EAAIoB,WAAWX,aAAa3B,OAAQkB,IAAK,OACjDV,KAAO8B,WAAWX,aAAaT,GACrCiB,YAAYf,KAAKZ,MAKnBI,QAAU0B,WAAWJ,aAAe,EAIpCE,eAAiBb,MAAQ,EAAIc,KAAKI,aAI/B,IAAIvB,EAAIN,QAASM,EAAIf,MAAMH,OAAQkB,IACtCiB,YAAYf,KAAKjB,MAAMe,WAGlBiB,YAAYS,KAAK,4HAIGhD,QAASC,SACb,iBAAZD,UACTA,SAAU,qBAAWA,cAGnBiD,aAAe,YACVC,mBACHC,MAAQnD,QAAQiD,oBACfE,aACIlD,QAAQmD,WAGjBnD,QAAQoD,SAASF,OAAO,SAASG,IAAKC,SAChCD,WACKrD,QAAQmD,SAASE,SAGtBE,eAAiB1D,WAAWyD,KAAMJ,MAAOlD,SAC7CA,QAAQwD,QAAQN,MAAOK,gBAAgB,SAASF,QAC1CA,WACKrD,QAAQmD,SAASE,KAG1BJ,qBAINA"}